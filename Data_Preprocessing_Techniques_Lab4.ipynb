{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVRG5A4BA9nUfWZDH/4oR7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Frank-Muzi/School-practice/blob/main/Data_Preprocessing_Techniques_Lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5NtFgYUV1i-",
        "outputId": "2a82a930-77e2-416d-a04f-6e728103d44f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      A     B     C    D\n",
            "0   1.0   2.0   3.0  4.0\n",
            "1   5.0   6.0   NaN  8.0\n",
            "2  10.0  11.0  12.0  NaN\n",
            "A    0\n",
            "B    0\n",
            "C    1\n",
            "D    1\n",
            "dtype: int64\n",
            "     A    B    C    D\n",
            "0  1.0  2.0  3.0  4.0\n",
            "      A     B\n",
            "0   1.0   2.0\n",
            "1   5.0   6.0\n",
            "2  10.0  11.0\n",
            "      A     B     C    D\n",
            "0   1.0   2.0   3.0  4.0\n",
            "1   5.0   6.0   NaN  8.0\n",
            "2  10.0  11.0  12.0  NaN\n",
            "     A    B    C    D\n",
            "0  1.0  2.0  3.0  4.0\n",
            "      A     B     C    D\n",
            "0   1.0   2.0   3.0  4.0\n",
            "2  10.0  11.0  12.0  NaN\n",
            "[[ 1.   2.   3.   4. ]\n",
            " [ 5.   6.   7.5  8. ]\n",
            " [10.  11.  12.   6. ]]\n",
            "    color  size  price classlabel\n",
            "0  yellow     0    9.5     class0\n",
            "1   green     1   10.1     class2\n",
            "2     red     2   13.5     class1\n",
            "3    blue     3   15.3     class2\n",
            "0     S\n",
            "1     M\n",
            "2     L\n",
            "3    XL\n",
            "Name: size, dtype: object\n",
            "[0 2 1 2]\n",
            "['class0' 'class2' 'class1' 'class2']\n",
            "[[3 0 9.5]\n",
            " [1 1 10.1]\n",
            " [2 2 13.5]\n",
            " [0 3 15.3]]\n",
            "[[0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]]\n",
            "   price  size  color_blue  color_green  color_red  color_yellow\n",
            "0    9.5     0       False        False      False          True\n",
            "1   10.1     1       False         True      False         False\n",
            "2   13.5     2       False        False       True         False\n",
            "3   15.3     3        True        False      False         False\n",
            "   price  size  color_green  color_red  color_yellow\n",
            "0    9.5     0        False      False          True\n",
            "1   10.1     1         True      False         False\n",
            "2   13.5     2        False       True         False\n",
            "3   15.3     3        False      False         False\n",
            "   Class label  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
            "0            1    14.23        1.71  2.43               15.6        127   \n",
            "1            1    13.20        1.78  2.14               11.2        100   \n",
            "2            1    13.16        2.36  2.67               18.6        101   \n",
            "3            1    14.37        1.95  2.50               16.8        113   \n",
            "4            1    13.24        2.59  2.87               21.0        118   \n",
            "\n",
            "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
            "0           2.80        3.06                  0.28             2.29   \n",
            "1           2.65        2.76                  0.26             1.28   \n",
            "2           2.80        3.24                  0.30             2.81   \n",
            "3           3.85        3.49                  0.24             2.18   \n",
            "4           2.80        2.69                  0.39             1.82   \n",
            "\n",
            "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
            "0             5.64  1.04                          3.92     1065  \n",
            "1             4.38  1.05                          3.40     1050  \n",
            "2             5.68  1.03                          3.17     1185  \n",
            "3             7.80  0.86                          3.45     1480  \n",
            "4             4.32  1.04                          2.93      735  \n",
            "Train shape: (142, 13) Test shape: (36, 13)\n",
            "[[0.12573099 0.02964427 0.65240642 0.3814433  0.2962963  0.42068966\n",
            "  0.39451477 0.16981132 0.61075949 0.11634103 0.32978723 0.66300366\n",
            "  0.17261056]\n",
            " [0.79239766 0.14624506 0.51336898 0.31958763 0.30864198 0.42068966\n",
            "  0.44092827 0.24528302 0.36392405 0.28952043 0.73404255 0.56776557\n",
            "  0.7146933 ]]\n",
            "[[-1.45083563 -1.27985582  0.74306024 -0.49136511 -0.37078043 -0.15558334\n",
            "   0.17965734 -1.20822065  1.29150989 -0.84486398 -0.74910758  0.66674895\n",
            "  -0.71247369]\n",
            " [ 1.34746381 -0.75756493 -0.2118226  -0.84257574 -0.29683265 -0.15558334\n",
            "   0.39838279 -0.87620839 -0.0490171  -0.00656951  0.99652401  0.29506888\n",
            "   1.63245344]]\n",
            "Training accuracy: 1.0\n",
            "Test accuracy: 1.0\n",
            "[[ 1.28498746  0.1740662   0.76339599 -1.26080394  0.          0.\n",
            "   1.21590437  0.          0.          0.          0.          0.6038188\n",
            "   2.59592002]\n",
            " [-1.52903486 -0.48650752 -1.09045004  0.58337002  0.          0.\n",
            "   0.57043419  0.073802    0.08553558 -2.12344519  1.00497315  0.\n",
            "  -2.32007942]\n",
            " [ 0.16081414  0.1403113   0.54334324  0.          0.          0.\n",
            "  -2.44001186  0.          0.          1.80387376 -1.06440408 -0.46606216\n",
            "   0.        ]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "csv_data = '''A,B,C,D\n",
        "1.0,2.0,3.0,4.0\n",
        "5.0,6.0,,8.0\n",
        "10.0,11.0,12.0,'''\n",
        "df = pd.read_csv(StringIO(csv_data))\n",
        "print(df)\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Drop rows with any missing values\n",
        "print(df.dropna(axis=0))\n",
        "\n",
        "# Drop columns with any missing values\n",
        "print(df.dropna(axis=1))\n",
        "\n",
        "# Drop rows where all values are missing (none in this case)\n",
        "print(df.dropna(how='all'))\n",
        "\n",
        "# Drop rows with fewer than 4 non-missing values\n",
        "print(df.dropna(thresh=4))\n",
        "\n",
        "# Drop rows where 'C' is missing\n",
        "print(df.dropna(subset=['C']))\n",
        "\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "\n",
        "imr = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imr = imr.fit(df.values)\n",
        "imputed_data = imr.transform(df.values)\n",
        "print(imputed_data)\n",
        "\n",
        "df = pd.DataFrame([\n",
        "    ['yellow', 'S', 9.5, 'class0'],\n",
        "    ['green', 'M', 10.1, 'class2'],\n",
        "    ['red', 'L', 13.5, 'class1'],\n",
        "    ['blue', 'XL', 15.3, 'class2']])\n",
        "df.columns = ['color', 'size', 'price', 'classlabel']\n",
        "\n",
        "size_mapping = {'XL': 3, 'L': 2, 'M': 1, 'S': 0}\n",
        "df['size'] = df['size'].map(size_mapping)\n",
        "print(df)\n",
        "\n",
        "# Inverse mapping\n",
        "inv_size_mapping = {v: k for k, v in size_mapping.items()}\n",
        "print(df['size'].map(inv_size_mapping))\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "class_le = LabelEncoder()\n",
        "y = class_le.fit_transform(df['classlabel'].values)\n",
        "print(y)\n",
        "\n",
        "# Inverse\n",
        "print(class_le.inverse_transform(y))\n",
        "\n",
        "X = df[['color', 'size', 'price']].values\n",
        "color_le = LabelEncoder()\n",
        "X[:, 0] = color_le.fit_transform(X[:, 0])\n",
        "print(X)\n",
        "\n",
        "# One-hot encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ohe = OneHotEncoder()\n",
        "print(ohe.fit_transform(X[:, [0]]).toarray())  # Only on 'color'\n",
        "\n",
        "# Using pandas get_dummies\n",
        "print(pd.get_dummies(df[['price', 'color', 'size']]))\n",
        "\n",
        "# Drop first column to avoid multicollinearity\n",
        "print(pd.get_dummies(df[['price', 'color', 'size']], drop_first=True))\n",
        "\n",
        "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\n",
        "df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium',\n",
        "                   'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',\n",
        "                   'Color intensity', 'Hue', 'OD280/OD315 of diluted wines', 'Proline']\n",
        "print(df_wine.head())\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
        "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "mms = MinMaxScaler()\n",
        "X_train_norm = mms.fit_transform(X_train)\n",
        "X_test_norm = mms.transform(X_test)\n",
        "print(X_train_norm[:2])  # First two rows\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "stdsc = StandardScaler()\n",
        "X_train_std = stdsc.fit_transform(X_train)\n",
        "X_test_std = stdsc.transform(X_test)\n",
        "print(X_train_std[:2])\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(penalty='l1', C=1.0, solver='liblinear')\n",
        "lr.fit(X_train_std, y_train)\n",
        "print('Training accuracy:', lr.score(X_train_std, y_train))\n",
        "print('Test accuracy:', lr.score(X_test_std, y_test))\n",
        "print(lr.coef_)\n",
        "\n",
        "\n",
        "# Because missing data can bias results, reduce accuracy, and mislead model training.\n",
        "# Use one-hot for nominal categories and label for ordinal categories.\n",
        "# It ensures fair distance or weight calculations since both are sensitive to feature magnitudes.\n",
        "# L1 automatically shrinks irrelevant feature weights to zero, while SBS removes features iteratively based on performance."
      ]
    }
  ]
}